# ğŸš€ Complete n8n Integration Setup Guide

## ğŸ¯ **What We've Built**

You now have a **complete, professional-grade n8n automation system** for your AI Data Platform:

- âœ… **Docker-based n8n** (running on localhost:5678)
- âœ… **Complete workflow JSON** (ready to import)
- âœ… **Full API integration** (programmatic workflow management)
- âœ… **Enhanced CLI commands** (with API key support)
- âœ… **Professional automation** (scheduled + manual triggers)

## ğŸš€ **Quick Start (3 steps)**

### **Step 1: Get Your n8n API Key**
```bash
# Run the helper script
python get_n8n_api_key.py

# Or manually:
# 1. Go to http://localhost:5678
# 2. Settings â†’ API Keys â†’ Create API Key
# 3. Copy the key (looks like: n8n_api_xxxxxxxxxxxxxxxx)
```

### **Step 2: Set Up the Workflow**
```bash
# Create and activate the workflow automatically
python -m ai_data_platform n8n setup --api-key YOUR_API_KEY_HERE
```

### **Step 3: Test Everything**
```bash
# Test connection
python -m ai_data_platform n8n test --api-key YOUR_API_KEY_HERE

# Check status
python -m ai_data_platform n8n status --api-key YOUR_API_KEY_HERE

# Run data ingestion
python -m ai_data_platform n8n ingest --api-key YOUR_API_KEY_HERE
```

## ğŸ”‘ **API Key Management**

### **Option 1: Environment Variable (Recommended)**
```bash
# Windows PowerShell
$env:N8N_API_KEY="your_api_key_here"

# Windows Command Prompt
set N8N_API_KEY=your_api_key_here

# Then run commands without --api-key flag
python -m ai_data_platform n8n setup
python -m ai_data_platform n8n test
```

### **Option 2: Command Line Parameter**
```bash
# Pass API key with each command
python -m ai_data_platform n8n setup --api-key your_api_key_here
python -m ai_data_platform n8n test --api-key your_api_key_here
```

## ğŸ“‹ **What Each Command Does**

### **`n8n setup`**
- ğŸ” Tests connection to n8n
- ğŸ“‹ Creates the data ingestion workflow
- ğŸš€ Activates the workflow automatically
- ğŸ“Š Returns workflow ID for future use

### **`n8n test`**
- ğŸ”Œ Tests n8n API connection
- ğŸ“‹ Lists all existing workflows
- ğŸŸ¢ Shows active/inactive status
- âœ… Confirms everything is working

### **`n8n status`**
- ğŸ“Š Shows detailed workflow information
- ğŸ“ˆ Lists recent executions
- ğŸ”„ Shows workflow version and metadata
- ğŸ“… Shows creation and update times

### **`n8n ingest`**
- ğŸš€ Triggers the data ingestion workflow
- ğŸ“ Processes the specified CSV file
- ğŸ”„ Runs the complete ETL pipeline
- ğŸ“Š Returns execution results

## ğŸ¯ **Workflow Features**

### **Automation Capabilities:**
- ğŸ“… **Daily Scheduler**: Runs automatically at 9 AM UTC
- ğŸ–±ï¸ **Manual Trigger**: Run anytime via CLI or n8n interface
- ğŸŒ **Webhook Support**: External triggers via HTTP
- ğŸ”„ **Error Handling**: Automatic failure notifications
- ğŸ“Š **Execution Monitoring**: Track all runs and results

### **Data Processing:**
- ğŸ“ **CSV Reading**: Processes ads_spend.csv
- ğŸ”„ **Data Transformation**: Adds metadata and timestamps
- ğŸŒ **ETL Integration**: Calls your local ETL pipeline
- âœ… **Success/Error Handling**: Comprehensive status reporting

## ğŸ³ **Docker Management**

### **Start/Stop n8n:**
```bash
# Start n8n
docker-compose up -d n8n

# Stop n8n
docker-compose stop n8n

# View logs
docker-compose logs -f n8n

# Restart
docker-compose restart n8n
```

### **Check Status:**
```bash
# Container status
docker-compose ps

# n8n logs
docker-compose logs n8n
```

## ğŸ”§ **Configuration Options**

### **Environment Variables:**
```bash
# n8n settings
N8N_BASE_URL=http://localhost:5678
N8N_API_KEY=your_api_key_here
N8N_WEBHOOK_SECRET=ai-platform-secret-2024

# AI Platform settings
API_HOST=127.0.0.1
API_PORT=8000
```

### **Customization:**
- **Change Schedule**: Edit the Cron node in n8n (currently: `0 9 * * *`)
- **Modify Endpoint**: Update HTTP Request node URL
- **Add Notifications**: Connect to email/Slack nodes
- **File Path**: Update CSV Reader node path

## ğŸ§ª **Testing Your Setup**

### **1. Connection Test:**
```bash
python -m ai_data_platform n8n test --api-key YOUR_KEY
```
**Expected Output:**
```
ğŸ” Testing n8n connection...
âœ… Successfully connected to n8n instance!
ğŸ“‹ Found X workflows:
  - AI Data Platform - Data Ingestion (ğŸŸ¢ Active)
```

### **2. Workflow Setup:**
```bash
python -m ai_data_platform n8n setup --api-key YOUR_KEY
```
**Expected Output:**
```
ğŸ” Testing n8n connection...
âœ… Connected to n8n successfully!
ğŸ“‹ Setting up data ingestion workflow...
ğŸ‰ Workflow created and activated successfully!
ğŸ“Š Workflow ID: workflow_xxxxxxxx
ğŸš€ Ready to run data ingestion!
```

### **3. Data Ingestion:**
```bash
python -m ai_data_platform n8n ingest --api-key YOUR_KEY
```
**Expected Output:**
```
ğŸš€ Triggering data ingestion workflow for ads_spend.csv...
âœ… Data ingestion workflow executed successfully!
ğŸ“Š Check n8n interface for execution details
```

## ğŸš¨ **Troubleshooting**

### **Common Issues:**

1. **"Cannot connect to n8n"**
   ```bash
   # Check if Docker is running
   docker ps
   
   # Start n8n
   docker-compose up -d n8n
   
   # Check logs
   docker-compose logs n8n
   ```

2. **"API key required"**
   ```bash
   # Get your API key from n8n
   python get_n8n_api_key.py
   
   # Or set environment variable
   $env:N8N_API_KEY="your_key_here"
   ```

3. **"Workflow not found"**
   ```bash
   # Set up the workflow first
   python -m ai_data_platform n8n setup --api-key YOUR_KEY
   ```

4. **"Permission denied"**
   ```bash
   # Check Docker permissions
   docker-compose down
   docker-compose up -d n8n
   ```

### **Debug Commands:**
```bash
# Test n8n connection directly
curl http://localhost:5678

# Check container status
docker-compose ps

# View n8n logs
docker-compose logs -f n8n

# Access n8n container
docker exec -it n8n-ai-platform bash
```

## ğŸ”® **Future Enhancements**

### **Immediate Next Steps:**
1. **Test the complete workflow** with real data
2. **Customize the schedule** to your needs
3. **Add email notifications** for success/failure
4. **Integrate with your AI platform** API

### **Advanced Features:**
- **Multiple data sources** (more CSV files)
- **Advanced scheduling** (multiple time slots)
- **Slack/Teams integration** for notifications
- **Monitoring dashboard** for workflow health
- **Data validation** and quality checks

## ğŸ‰ **Success Indicators**

### **Everything is Working When:**
- âœ… n8n accessible at http://localhost:5678
- âœ… API key authentication successful
- âœ… Workflow created and activated
- âœ… Manual execution successful
- âœ… Scheduled execution running
- âœ… ETL pipeline receiving requests
- âœ… Success/error notifications working

## ğŸ“ **Getting Help**

### **If You Need Support:**
1. **Check logs**: `docker-compose logs n8n`
2. **Test connection**: `python -m ai_data_platform n8n test --api-key YOUR_KEY`
3. **Verify workflow**: `python -m ai_data_platform n8n status --api-key YOUR_KEY`
4. **Review this guide**: All common issues covered

---

## ğŸš€ **You're Ready to Go!**

**Your n8n automation system is now:**
- ğŸ³ **Running in Docker** (no trial limitations)
- ğŸ”‘ **Fully API-enabled** (complete automation)
- ğŸ“‹ **Workflow-ready** (import with one command)
- ğŸš€ **Production-ready** (professional-grade setup)

**Next command to run:**
```bash
python get_n8n_api_key.py
```

**Then:**
```bash
python -m ai_data_platform n8n setup --api-key YOUR_API_KEY
```

**ğŸ¯ You'll have a fully automated data ingestion system!**

